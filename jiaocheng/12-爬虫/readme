一、“大数据时代”获取数据的方式
1.企业生产的用户数据：大型互联网公司有海量用户，有数据意识的中小型企业也开始积累数据
2.数据管理咨询公司
3.政府、机构提供的公开数据
4.第三方数据平台购买
5.爬虫爬取数据

二、什么是爬虫
爬取网页数据的程序

三、爬虫怎么爬取网页数据：
网页3大特征：1.每个网页都有自己的URL来进行定位
             2.网页都是用html来描述网页信息
             3.网页都使用HTTP/HTTPS协议来传输HTML数据
爬虫的设计思路
    1.首先确定需要爬取的网页的URL地址
    2.通过HTTP/HTTPS协议来获取对应的HTML数据
    3.提取HTML页面里对自己来说有用的数据
        a.如果是需要的数据，就保存起来
        b.如果是页面的其他URL，那就继续执行第二步

四、为什么选python做爬虫
做爬虫的变成语言有很多，如PHP、java、C、Python等等
    PHP是做web的
    
五、通用爬虫、聚焦爬虫
通用爬虫：搜索引擎用的爬虫系统
    目标：尽可能把互联网上的所有网页下载下来，放到本地服务器里，再对这些网页做相关处理，最后提供一个用户检索接口
    抓取流程：
        1.选取一部分已有的URL，放到待爬取队列
        2.从队列中取出URL，然后解析 dns得到主机ip，到ip对应的服务器下载HTML页面，保存到搜索引擎的本地服务器
        之后把这个爬过的URL放入已爬取队列
        3.分析这些网页内容，找出网页里其他的URL链接，继续执行第二步，知道结束

    搜索引擎如何获取新网站的URL
        1.主动向搜索引擎提供地址
        2.在其他网站设置网站的外链
        3.搜索引擎会和dns服务商合作，快速收录新的网站

    通用爬虫并不是万物皆可爬取，需要遵守规定
        robots协议：协议会指明通用爬虫可以爬取网页的权限。例如https://www.taobao.com/robots.txt
        这个协议不是所有爬虫都遵守，一般只有大型的搜索引擎爬虫会遵守，个人写的不用管

    通用爬虫工作流程：爬取网页--存储数据--内容处理--提供检索/排名服务

    搜索引擎排名：
        PageRank值：根据网站流量（点击量，浏览量，人气）统计，流量越高，排名越靠前
        竞价排名：看谁给钱多

    缺点：只能提供和文本相关的内容，不能提供多媒体文件和二进制文件（程序，脚本）
          提供的结果千篇一律，不能针对不同领域的人提供不同的搜索
          不能理解人类语义上的检索

为了解决上述问题，从而使用聚焦爬虫          
聚焦爬虫：爬虫程序员写的针对某种内容爬虫
    面向主题，需求，针对某些特定的内容去爬取信息，保证信息和需求尽可能相关


GET和POST请求的区别：
    GET: 请求的url会附带查询参数，查询参数在QueryString里保存
    POST：请求的url不带参数，查询参数在from表单里保存

做爬虫最需要关注的不是页面信息，而是页面信息的来源

Ajax方式加载的页面，数据来源就是json，拿到json就拿到了页面数据

